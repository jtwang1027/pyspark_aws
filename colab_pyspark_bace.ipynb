{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_pyspark_bace.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14c6USHfUfcRO8GUOzyeAQCMF8rQiBcL-",
      "authorship_tag": "ABX9TyN4JwSCvzO65s5GBlPJFzv6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jtwang1027/pyspark_aws/blob/master/colab_pyspark_bace.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKUxDHTCXvpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install pyspark\n",
        "#check that the spark version is avail at the wget URL, may be updated\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.5-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQnhuLy4ZgxO",
        "colab_type": "text"
      },
      "source": [
        "references to setup pyspark:\n",
        "- [(link1)](https://towardsdatascience.com/a-neanderthals-guide-to-apache-spark-in-python-9ef1f156d427)\n",
        "- [(link2)](https://www.youtube.com/watch?v=QUiAc3rWtMA)\n",
        "~41min\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUwT41DBcRY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#python packages\n",
        "'''\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error \n",
        "'''\n",
        "#pyspark packages\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n",
        "#from pyspark import SparkFiles\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "from pyspark.ml.feature import StandardScaler\n",
        "from pyspark.sql.functions import col, expr\n",
        "\n",
        "\n",
        "\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AL3FDkmaed_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"spark_instance\") \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf95hqIDcGu8",
        "colab_type": "code",
        "outputId": "f2cbade9-cf91-4574-a6a9-48b9ad9454ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pd_df= pd.read_csv('https://github.com/jtwang1027/pyspark_aws/raw/master/bace.csv')\n",
        "pd_df.drop('canvasUID',axis=1,inplace=True)\n",
        "pd_mol2vec=pd.read_csv('https://github.com/jtwang1027/pyspark_aws/raw/master/mol2vec.csv',header=None)\n",
        "\n",
        "#concatenating two df (adding columsn) is a pain in Spark, we'll just do it pandas\n",
        "pd_comb=pd.concat([pd_df,pd_mol2vec],axis=1)\n",
        "print(pd_comb.shape) #594 cols from w2v + 300 col from w2v"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1513, 894)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVIWnaKU6eqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#going from URL directly to spark df example\n",
        "#url2='https://github.com/jtwang1027/pyspark_aws/raw/master/mol2vec.csv'\n",
        "#spark.sparkContext.addFile(url2)\n",
        "#temp = spark.read.csv(\"file://\"+SparkFiles.get(\"mol2vec.csv\"), header=False, inferSchema= True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z7F52JVziK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checking distribution of pIC50 across train/test validation groups\n",
        "sns.violinplot(pd_df.Model, pd_df['pIC50'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgfyZx2rcG6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=spark.createDataFrame(pd_df) \n",
        "df_m2v=spark.createDataFrame(pd_comb) #df + mol2vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0ko5exkiWTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "#rename columns to replace periods . and parentheses, which would trigger syntax error in Pyspark\n",
        "df=df.toDF(*(re.sub(r'[\\.\\s]+', '', c) for c in df.columns))\n",
        "df=df.toDF(*(re.sub(r'\\([^)]*\\)', '', c) for c in df.columns))\n",
        "\n",
        "df_m2v=df_m2v.toDF(*(re.sub(r'[\\.\\s]+', '_', c) for c in df_m2v.columns))\n",
        "df_m2v=df_m2v.toDF(*(re.sub(r'\\([^)]*\\)', '_', c) for c in df_m2v.columns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXDXAI3mcHAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining Pipeline for: df\n",
        "assembler=VectorAssembler(inputCols= df.columns[5:], outputCol= 'pre-scaled')\n",
        "scaling= StandardScaler(inputCol='pre-scaled', outputCol='features', withStd=True, withMean=False)\n",
        "pipeline1= Pipeline( stages=[assembler, scaling])\n",
        "\n",
        "#second assembler for m2v with additional columns (has more columns that has to be assembled)\n",
        "assembler2=VectorAssembler(inputCols= df_m2v.columns[5:], outputCol= 'pre-scaled')\n",
        "pipeline2= Pipeline( stages=[assembler2, scaling])\n",
        "\n",
        "#fitting pipeline on both datasets\n",
        "df_scaled=pipeline1.fit(df).transform(df)\n",
        "df_m2v_scaled=pipeline2.fit(df_m2v).transform(df_m2v)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecU3uCEZaGdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting into train/test/validation, predefined for this dataset based on Model column\n",
        "train= df_scaled.filter(col('Model')=='Test') #\"Test\" has more rows, use for training\n",
        "test= df_scaled.filter(col('Model')=='Train') #203 rows\n",
        "validation= df_scaled.filter(col('Model')=='Valid') #45 rows\n",
        "\n",
        "#train/test/split the second dataframe \n",
        "train_m2v= df_m2v_scaled.filter(col('Model')=='Test') #\"Test\" has more rows, use for training\n",
        "test_m2v= df_m2v_scaled.filter(col('Model')=='Train') #203 rows\n",
        "validation_m2v= df_m2v_scaled.filter(col('Model')=='Valid') #45 rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AgnTydMMJiS",
        "colab_type": "code",
        "outputId": "6d6d2742-191d-444e-e43d-01876b532a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "train_m2v.select('Model').show(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|Model|\n",
            "+-----+\n",
            "| Test|\n",
            "| Test|\n",
            "| Test|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsV4mHs7LCa9",
        "colab_type": "text"
      },
      "source": [
        "## Linear Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTM6Fwq8H_Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr=LinearRegression(labelCol='pIC50').fit(train)\n",
        "lr_model=lr.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gui6uLvOIAih",
        "colab_type": "code",
        "outputId": "1aca639b-735d-44fd-c365-73d2b7fbdebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "lr_model.select('prediction','pIC50').show(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+---------+\n",
            "|       prediction|    pIC50|\n",
            "+-----------------+---------+\n",
            "|7.413925713777616|9.1549015|\n",
            "|8.003503019102709|8.8538723|\n",
            "|8.213082908073588|8.6989698|\n",
            "|7.835343812156019|8.6989698|\n",
            "|8.206335882401547|8.6989698|\n",
            "+-----------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q81dfdZgYkSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#regparam= lambda, weight of regularization\n",
        "#elasticNetParam= alpha, weighting of L1 vs L2 norm\n",
        "enet=LinearRegression(featuresCol='features', labelCol='pIC50')\n",
        "paramGrid=(ParamGridBuilder()\n",
        "             .addGrid(enet.regParam, [0.01, 0.01, 0.5, 0.9])\n",
        "             .addGrid(enet.elasticNetParam, [0.0,0.25, 0.5,0.75, 1.0])\n",
        "             .addGrid(enet.maxIter, [10])\n",
        "             .build())\n",
        "\n",
        "evaluator=RegressionEvaluator( predictionCol='prediction',labelCol='pIC50',metricName='rmse')\n",
        "\n",
        "cv = CrossValidator(estimator=enet, estimatorParamMaps=paramGrid,\n",
        "                    evaluator=evaluator, numFolds=5)\n",
        "\n",
        "cvMod=cv.fit(train)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGekJrBrYkPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enet_best=cvMod.bestModel\n",
        "enet_pred=enet_best.transform(test)\n",
        "#cvMod.bestModel.getParam('regParam')\n",
        "#cvMod.bestModel.getParam('elasticNetParam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgvZEsFXuTk2",
        "colab_type": "code",
        "outputId": "b0d8a802-cf54-4c71-ee6b-27c463b8de60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#2 ways to evaluate linear regression output\n",
        "#1) using the regressionevaluator\n",
        "evaluator.evaluate(enet_pred)\n",
        "\n",
        "#evaluate method\n",
        "enet_best=cvMod.bestModel\n",
        "enet_summ=enet_best.evaluate(test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27.587484403720904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmezyMkHzPKh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enet_pred.select('prediction','pIC50','mol').show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TlFA8XnvuDJ",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosted Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5w-i_OmhdY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.regression import GBTRegressor\n",
        "\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGe7aaGkYkM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify a GBT model\n",
        "gbt_model = GBTRegressor(featuresCol=\"features\", maxIter=10,labelCol='pIC50',  predictionCol='prediction')\n",
        "# GBT training\n",
        "gbt = gbt_model.fit(train)\n",
        "\n",
        "gbt_m2v = gbt_model.fit(train_m2v)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLhgSpvgLwfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gbt_pred_m2v.select('prediction').show(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK7xcu-kwYKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Make predictions.\n",
        "#gbt_pred = gbt.transform(validation)\n",
        "gbt_pred_m2v = gbt_m2v.transform(validation_m2v)\n",
        "\n",
        "# Select example rows to display.\n",
        "#gbt_pred.select(\"prediction\", \"pIC50\").show(5)\n",
        "\n",
        "evaluator=RegressionEvaluator( predictionCol='prediction', labelCol='pIC50',metricName='rmse')\n",
        "\n",
        "# Select (prediction, true label) and compute test error\n",
        "#rmse=evaluator.evaluate(gbt_pred)\n",
        "rmse_m2v=evaluator.evaluate(gbt_pred_m2v)\n",
        "\n",
        "\n",
        "\n",
        "#gbtModel = model.stages[1]\n",
        "#print(gbtModel)  # summary only"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk2arzqgKVY1",
        "colab_type": "code",
        "outputId": "42351dcf-17ce-4dad-ffc7-6b4f3e8a67d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#gbt_m2v.select('features','pIC50').show(5)\n",
        "#gbt_pred_m2v.select('prediction','pIC50').show(5)\n",
        "gbt_pred_m2v.count()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GDsw0U3YkH0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Root Mean Squared Error (RMSE) on est data = %g\" % rmse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv2HoLqZYkEz",
        "colab_type": "code",
        "outputId": "28c6e00a-e2c0-4c14-cafa-10ff9c584164",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "rmse_m2v"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-de69f5762304>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse_m2v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'rmse_m2v' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYbaWveeYj_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECsbyk-alMKE",
        "colab_type": "text"
      },
      "source": [
        "pretty good pandas_udf tutorial\n",
        "[(link)](https://towardsdatascience.com/pyspark-forecasting-with-pandas-udf-and-fb-prophet-e9d70f86d802)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNPgNnN8g8w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.schema.fieldNames()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_etRhB4uTNqh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rdkit import Chem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jx2c1F2FhPq5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install word2vec \n",
        "!pip install git+https://github.com/samoturk/mol2vec\n",
        "\n",
        "#install rdkit dependencies, and deepchem if needed\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c conda-forge rdkit "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXMlmz1LU9B8",
        "colab_type": "code",
        "outputId": "04fb1309-6412-4a00-9005-228b5ed19343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#install rdkit dependencies, and deepchem if needed\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c conda-forge rdkit "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zehjC5ePVNoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import rdkit"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}